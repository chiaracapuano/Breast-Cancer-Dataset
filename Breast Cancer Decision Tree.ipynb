{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Breast Cancer Wisconsin (Diagnostic) Data Set contains 30 columns and 569 rows, corresponding to 569 samples\n",
    "of biopsied tissue. The tissue for each sample is an image, and 10 characteristics of the nuclei of cells present\n",
    "in each image are characterized according to the following parameters:\n",
    "\n",
    "1. Radius\n",
    "2. Texture\n",
    "3. Perimeter\n",
    "4. Area\n",
    "5. Smoothness\n",
    "6. Compactness\n",
    "7. Concavity\n",
    "8. Number of concave portions of contour\n",
    "9. Symmetry\n",
    "10. Fractal dimension\n",
    "\n",
    "The following ten columns contain the standard deviation of each of the attributes from 1 to 10 and the last ten columns indicate the maximum measurement of the correspond feature 1-10 obtained in a single image.\n",
    "\n",
    "The dataset is divided already in (X_train, Y_train) and (X_test, Y_test) sets, where the Y sets are either 0 or 1, depending on whether the tissue was found to be benign or malignant.\n",
    "\n",
    "This is a classification problem, which involves a binary choice, based on several parameters.\n",
    "\n",
    "The initial approach will be training a Decision Tree using all the parameters available. The quality of the training model will be calculated via the area under the ROC curve. \n",
    "\n",
    "Thanks to the function GridSearchCV, I am able to observe how the quality of the model changes for different settings of the Decision Tree input parameters, like the max_depth, which is the maximum depth that the tree can achieve. \n",
    "\n",
    "My suspicion is that using all the attributes of the training set blindly generates a loss of information which is quite crucial: the standard deviation and maximum values of the attributes are intrinsically related to the attributes themselves, so it is necessary to find a way to communicate this relationship to the model. A bit like what happens when fitting some raw data with errors included to a model: the presence of the errors helps determining the model more accurately.\n",
    "\n",
    "The variable I though of introducing for each of the ten attributes is what I very boringly called \"attributes_relations_[i]\", and is simply defined as: (attribute[max]-attribute[mean])/attribute[std]. Basically I am determining how many standard deviations from the maximum value of the feature measured the mean is. I don't have any background in the subject treated, but I would argue that a mean value close to the maximum value implies that the attribute is homogeneous: an average radius of 2mm with maximum radius of 10mm tells me that the feature observed is extremely irregular, which I understand not being good news.\n",
    "\n",
    "In the following I will present my analysis step by step and draw some conclusions.\n",
    "\n",
    "1)First things first. Load the data and rename all the columns with the name of the feature rather than a number, and check the quality of the datasets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "trainY= pd.read_csv('trainY.csv', header=None)\n",
    "trainX= pd.read_csv('trainX.csv', header=None)\n",
    "testY= pd.read_csv('testY.csv', header=None)\n",
    "testX= pd.read_csv('testX.csv', header=None)\n",
    "\n",
    "#new names for the colums for train and test datasets\n",
    "trainX.columns = ['Radius','Texture','Perimeter','Area','Smoothness','Compactness','Concavity',\n",
    "                  'Number of concave portions of contour','Symmetry','Fractal dimension',\n",
    "                  'std_Radius', 'std_Texture', 'std_Perimeter', 'std_Area', 'std_Smoothness', 'std_Compactness',\n",
    "                  'std_Concavity',\n",
    "                  'std_Number of concave portions of contour', 'std_Symmetry', 'std_Fractal dimension',\n",
    "                  'max_Radius', 'max_Texture', 'max_Perimeter', 'max_Area', 'max_Smoothness', 'max_Compactness',\n",
    "                  'max_Concavity',\n",
    "                  'max_Number of concave portions of contour', 'max_Symmetry', 'max_Fractal dimension'\n",
    "                  ]\n",
    "testX.columns = ['Radius','Texture','Perimeter','Area','Smoothness','Compactness','Concavity',\n",
    "                  'Number of concave portions of contour','Symmetry','Fractal dimension',\n",
    "                  'std_Radius', 'std_Texture', 'std_Perimeter', 'std_Area', 'std_Smoothness', 'std_Compactness',\n",
    "                  'std_Concavity',\n",
    "                  'std_Number of concave portions of contour', 'std_Symmetry', 'std_Fractal dimension',\n",
    "                  'max_Radius', 'max_Texture', 'max_Perimeter', 'max_Area', 'max_Smoothness', 'max_Compactness',\n",
    "                  'max_Concavity',\n",
    "                  'max_Number of concave portions of contour', 'max_Symmetry', 'max_Fractal dimension'\n",
    "                  ]\n",
    "\n",
    "#Check for presence of non-float values (I'm expecting every value is a float)\n",
    "\n",
    "trainX.info()\n",
    "testX.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)I want to train the dataset with a decision tree, but I don't know which depth is optimal, that is, when it is best to prune the tree to avoid overfitting. \n",
    "All I know is that the minimum depth must be ⌈log2(n)+1⌉ where n is the number of samples (569 in this case), so thanks to the function GridSearchCV() I can set the depth to different values and obtain the optimal depth: the depth for which the quality of the model (AUC ROC) is highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "treeCheck = tree.DecisionTreeClassifier(random_state=0)\n",
    "parameters={'max_depth': [11,15,20,25,30,35]}\n",
    "clf = GridSearchCV(treeCheck, parameters, scoring='roc_auc', cv=3)\n",
    "clf.fit(x, y)\n",
    "\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best estimator results to be..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=11, #here's the tree depth\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
    "            splitter='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a Decision Tree with minimum depth.\n",
    "\n",
    "3)I calculate the AUC ROC curve obtained predicting the data in testX with a Decision Tree with max_depth=11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "pred=clf.predict(testX)\n",
    "fpr, tpr, thresholds = roc_curve(testY, pred) \n",
    "aucroc=auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I obtain AUC ROC=0.8375. \n",
    "Let's see if I can improve it introducing the variable \"attributes_relations_[i]\".\n",
    "\n",
    "4)I add the 10 new columns containing \"attributes_relations_[i]\" for every feature, both to the train and test X data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "\n",
    "            newCol = (testX[testX.columns[20+i]] - testX[testX.columns[i]])/testX[testX.columns[10+i]] #(max-mean)/std\n",
    "            testX['attributes_relations_' + str(list_ib[i]) ] = newCol \n",
    "            \n",
    "            \n",
    "\n",
    "for i in range(0,10):\n",
    "\n",
    "            newCol = (trainX[trainX.columns[20+i]] - trainX[trainX.columns[i]])/trainX[trainX.columns[10+i]] #(max-mean)/std\n",
    "            trainX['attributes_relations_' + str(list_ib[i]) ] = newCol "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the only attributes of the data set I am interested to are given by the mean values of the features and their \"attribute_relations_[i]\" value, so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ib = trainX.columns.values\n",
    "attributes=[]\n",
    "count=-1\n",
    "for i in list_ib:\n",
    "    count=count+1\n",
    "    if count<10 or count>29:\n",
    "     attributes.append(i) #the only attributes I care about are in the first ten and last ten columns\n",
    "    \n",
    "    \n",
    "trainSet=trainX[attributes]\n",
    "testSet=testX[attributes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because some mean, max and standard deviation values are 0 (like for the attribute 'Concavity' in line 223 of the training set), the new set of columns will have some Nan. I eliminate them and replace them with 0 (testSet/trainSet.fillNa(0)).\n",
    "\n",
    "5)As above, I use GridSearchCV() to determine the tree optimal depth. The code is the same and also the result.\n",
    "\n",
    "So I train the Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=11,random_state=0)\n",
    "clf.fit(trainSet, y)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "pred=clf.predict(testSet)\n",
    "fpr, tpr, thresholds = roc_curve(testY, pred) \n",
    "aucroc=auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC ROC result is of 0.86, which is slightly higher than what obtained previously. \n",
    "\n",
    "This means that some information gets lost if we don't consider the intrinsic relation among the variables.\n",
    "\n",
    "6)Finally, let's see if it is true that if there is a big difference between mean and max value of a feature (like the radius) then the tissue is cancerous. \n",
    "\n",
    "To find out, I produce a scatter-plot of the \"attributes_relations_[Radius]\" versus \"Radius\" for both the real data and the data predicted by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the index of the 0 (benign) and 1 (malignant) values from the actual data\n",
    "ind_negatives=testY[0][testY[0]==0].index\n",
    "ind_pos=testY[0][testY[0]==1].index\n",
    "\n",
    "#get the index of the 0 (benign) and 1 (malignant) values from the predicted data\n",
    "import numpy as np\n",
    "ind_posModel =  np.nonzero(pred)[0]\n",
    "ind_negativesModel = np.where(pred == 0)[0]\n",
    "\n",
    "#plot\n",
    "import pylab as plt\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(testSet['attributes_relations_Radius'][ind_negatives],testSet['Radius'][ind_negatives],'bo',label='Benign')\n",
    "plt.plot(testSet['attributes_relations_Radius'][ind_pos],testSet['Radius'][ind_pos],'ro', label='Malignant')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Radius (mm)')\n",
    "plt.ylabel('(MaxRadius-MeanRadius)/StdRadius')\n",
    "plt.title('Actual data')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(testSet['attributes_relations_Radius'][ind_negativesModel],testSet['Radius'][ind_negativesModel],'bo',label='Benign')\n",
    "plt.plot(testSet['attributes_relations_Radius'][ind_posModel],testSet['Radius'][ind_posModel],'ro', label='Malignant')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Radius (mm)')\n",
    "plt.ylabel('(MaxRadius-MeanRadius)/StdRadius')\n",
    "plt.title('Predicted by Decision Tree')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is the following:\n",
    "\n",
    "![title](C:/Users/adach/Desktop/ModelandData.PNG)\n",
    "\n",
    "As it can be seen, in general this criterion is a good predictor, but not always. \n",
    "\n",
    "It can be noticed how the Decision Tree delivers false negatives in almost 10% of the cases, meaning that either the data set needs to be widened, or that another predictor should be found."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
